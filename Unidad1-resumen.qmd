---
title: "Resumen-cap1-2"
format: pdf
editor: visual
author: "Nelson Sarmiento","Nayeli Ramon", "Valeria Ulloa"
---

## Los orígenes del aprendizaje

Las primeras bases de datos han sido registradas por el entorno observable, ya que primero se observa y luego se registra en papel, pero hoy en día estos datos son registrados a través de bases de datos computarizadas que han ido en constante crecimiento.

Un aporte para estas bases ha sido la invención de los sensores, los cuales procesan los datos de manera muy distinta a una persona sin necesidad de traducción al lenguaje humano, los datos sensoriales en bruto siguen siendo objetivos.

Los cuales se han implementado en el campo de estudio interesado en el desarrollo de algoritmos informáticos para la transformación de datos en acciones inteligentes se conoce como aprendizaje automático. El constante crecimiento de los datos requería potencia informática adicional, lo que a su vez estimuló el desarrollo de métodos estadísticos para analizar grandes conjuntos de datos. Esto creó un ciclo de avance que permitió recopilar datos aún más grandes e interesantes.

## Usos y abusos del aprendizaje automático

El aprendizaje automático por lo general es utilizado para:

• Predecir los resultados de las elecciones

• Identifique y filtre los mensajes de spam del correo electrónico

• Prever actividad delictiva

• Automatice las señales de tráfico de acuerdo con las condiciones de la carretera

• Producir estimaciones financieras de tormentas y desastres naturales

• Examinar la rotación de clientes

• Crea aviones de pilotaje automático y coches de conducción automática.

• Identificar personas con capacidad para donar

• Dirigir la publicidad a tipos específicos de consumidores

Para ello un algoritmo de aprendizaje automático toma datos e identifica patrones que se pueden usar para la acción. En algunos casos, los resultados son tan exitosos que parecen alcanzar un estatus casi legendario.

Pero a su vez los datos de varias personas son usado para un algoritmo de aprendizaje automático que aprende patrones típicos de comportamiento que luego se pueden usar para hacer recomendaciones.

### **CONSIDERACIONES ÉTICAS**

Para usar de manera los algoritmos se debe tener precaución al obtener o analizar datos para evitar infringir leyes, violar términos de servicio o acuerdos de uso de datos, abusar de la confianza o violar la privacidad de los clientes o del público. Por cual se usa ciertas jurisdicciones que pueden impedir usar datos raciales, étnicos, religiosos u otras clases.

Tomando en cuenta que excluir datos personales puede no ser suficiente, debido que algunos algoritmos de aprendizaje automático pueden aprender esta información de forma independiente sin darse cuenta

### **CÓMO APRENDEN LAS MAQUINAS**

El aprendizaje de una maquina tiene un procedimiento similar a un humano, esta se puede dividir de la siguiente manera

-   Entrada de datos: es la observación, almacenamiento de memoria y recuerdo para proporcionar una base fáctica para un razonamiento posterior.

-   Abstracción: Implica la traducción de datos en representaciones más amplias.

-   Generalización: Utiliza datos abstractos parra formar una base para la acción

Las estrategias de aprendizaje comúnmente utilizadas para crear un esquema o un mapa conceptual son similares a cómo una máquina realiza la abstracción del conocimiento.

En los seres humanos, todo el proceso ocurre de manera subconsciente. Recordamos, deducimos, inducimos e intuimos. Sin embargo, para una computadora, estos procesos deben hacerse explícitos. Por otro lado, este es un beneficio del aprendizaje automático. Debido a que el proceso es transparente, el conocimiento aprendido se puede examinar y utilizar para acciones futuras.

### **ABSTRACCION Y REPRESENTACION DEL CONOCIMEINTO**

La abstracción de datos tiene el trabajo de asignar un significado a los datos, mientras que la representación del conocimiento es la formación de estructuras lógicas que ayudan a convertir la información sensorial en bruto en una percepción significativa.

Capacitación: Proceso de ajustar un modelo particular a un conjunto de datos.

### **GENERALIZACIÓN**

El término generalización describe el proceso de convertir el conocimiento abstracto en una forma que se puede utilizar para la acción. Específicamente, si imagina un conjunto hipotético que contiene todas las teorías posibles que podrían establecerse a partir de los datos, la generalización implica la reducción de este conjunto a un número manejable de hallazgos importantes.

El algoritmo empleará heurística, o conjeturas informadas sobre dónde encontrar los conceptos más importantes.

Pero también se debe tomar en cuenta que las heurísticas empleadas por los algoritmos de aprendizaje automático también dan lugar a veces a conclusiones erróneas. Si las conclusiones son sistemáticamente imprecisas, se dice que el algoritmo tiene una inclinación

### **EVALUAR EL ÉXITO DEL APRENDIZAJE**

Una vez que un modelo ha sido entrenado en un conjunto de datos inicial, el modelo se prueba en un nuevo conjunto de datos y se juzga en qué medida su caracterización de los datos de entrenamiento se generaliza a los nuevos datos

En parte, el hecho de que los modelos no generalicen perfectamente se debe al problema de ruido, o variaciones inexplicables en los datos. Tales como:

• Error de medición debido a sensores imprecisos que a veces suman o restan

un bit de la lectura

• Problemas con los datos de informes, como que los encuestados informen respuestas aleatorias a

las preguntas de la encuesta para terminar más rápido

• Errores causados cuando los datos se registran incorrectamente, incluidos valores faltantes, nulos,

truncados, codificados incorrectamente o dañados

Se dice que un modelo que parece funcionar bien durante el entrenamiento, pero lo hace mal durante las pruebas está sobre ajustado al conjunto de datos de entrenamiento, ya que no se generaliza bien.

### **PASOS PARA APLICAR EL APRENDIZAJE AUTOMÁTICO A SUS DATOS**

1.  Recolectando datos: los datos registrados ya sea en una hoja de papel o en hojas de cálculo, se deberá pasarse a un formato electrónico adecuado para el análisis, de tal manera que los datos nos sirvan como material de aprendizaje que utiliza un algoritmo para generar conocimiento procesable
2.  Exploración y preparación de los datos: Para la preparación de datos se necesita una calidad alta en los datos que se utilizan, debido a que un 80% del aprendizaje automático se dedica a aprender más de los mismos y sus matices mediante la exploración de datos.
3.  Entrenamiento de un modelo en los datos: Una vez preparados los datos para el análisis, se podrá tener una idea mas clara sobre lo que se espera aprender de dichos datos.  Lo cual se transmitirá a través de un algoritmo apropiado que representará los datos en forma de modelo
4.  Evaluación del rendimiento del modelo: Es importante evaluar el aprendizaje del algoritmo a partir de su experiencia. Este se puede evaluar mediante la precisión del modelo para desarrollar medidas de rendimiento específicas para la aplicación.
5.  Mejora del rendimiento del modelo: En caso de ser necesario un mejoramiento del modelo, se utiliza estrategias más avanzadas para un mayor rendimiento del modelo, además de ayudarse con datos adicionales y en últimos casos cambiar completamente el modelo

### **ELEGIR UN ALGORITMO DE APRENDIZAJE AUTOMÁTICO**

Para poder elegir un algoritmo adecuado de manera eficiente, se hace coincidir las características de los datos de los enfoques disponibles. Por lo cual es útil pensar en este procedimiento mientras se recopila, explora y limpia los datos.

### **PENSANDO EN LOS TIPOS DE ALGORITMOS DE APRENDIZAJE AUTOMÁTICO**

Los algoritmos de aprendizaje automático se dividen en:

-   Modelo Predictivo: Usado para tareas de predicción de un valor usando otros valores en el conjunto de datos. El algoritmo de aprendizaje intenta descubrir y modelar la relación entre el objetivo característico recibiendo instrucciones claras sobre lo que necesitan aprender y cómo deben aprenderlo, el proceso de entrenamiento de un modelo predictivo se conoce como aprendizaje supervisado.

-   Modelo Descriptivo: se utiliza para tareas que se beneficiarían de la información obtenida al resumir datos de formas nuevas e interesantes. A diferencia de los modelos predictivos que predicen un objetivo de interés, manteniendo la misma importancia para todas las características de dicho objetivo. De tal manera que el modelo también es llamado aprendizaje sin supervisión

### HACER COINCIDIR SUS DATOS CON UN ALGORITMO APROPIADO

En la tabla 1 se pueden observar los tipos generales de algoritmos:

![Figura 1. Tipos de algoritmos](Tipos%20de%20algoritmos.png)

Para hacer doincidir una tarea de aprendizaje con un enfoque autom\[atico es necesario comenzar con 4 tipos de tareas:

-   Clasificación

-   Predicción numérica

-   Detección de patrones

-   Agrupación

#### Uso de R para el aprendizaje automático

Es una herramienta muy util para el el aprendizaje automático y gracias a que es un código abierto no hay cargo adicional por funcionalidad, una comunidad de expertos que contribuyen al software.

### Instalación y carga de paquetes R

La forma más directa de instalar un paquete es con la función install.packages( ).

$$>install.packages("RWeka")$$

R se conectará a CRAN y descargará el paquete en el formato correcto para su sistema operativo.

Si necesita instalar un paquete desde otra ubicación se puede usar el siguiente comando:

$$>install.packages("RWeka", lib="/path/to/library")$$

# Gestión y comprender los datos

### Estructuras de datos R

Las estructuras de datos que se utilizan en R están diseñadas con el fin de facilitar la manipulación de los datos, las estructuras más utilizadas son: vectores, factores, listas, matrices y data frames.

### Vectores

Estructura fundamental, almacena un conjunto ordenado de valores llamdo elementos. Dentro del vector todos los elementos deben ser del mismo tipo.

Existen varios tipos de vectores:

-   Entero: sin decimales

-   Numérico: con decimales

-   Personajes: datos de texto

-   Lógico: Verdadero o falso

Para la creación de vectores se puede utilizar:

```{r}
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1, 98.6,101.4)
flu_status <- c(FALSE, FALSE, TRUE)
```

Para lograr extraer un dato específico se utiliza el comando:

```{r}
temperature[2]
temperature[2:3]
```

Para excluir valores se puede utilizar el símbolo (-):

```{r}
temperature[-2]
```

Otra forma para excluir datos es con el siguiente comando:

```{r}
temperature[c(TRUE, TRUE, FALSE)]
```

### Factores

Los rasgos que representan una características con categorías de valores son llamdos nominales.

Para este tipo de datos existe una estructura específica en R conocida como factor, este es un caso especial de vector.

Para crear un factor a partir de un vector de character se debe aplicar *factor ( )*

```{r}
gender <- factor(c("MALE","FEMALE", "MALE"))
gender
```

Los niveles comprenden un conjunto de posibles categor\[ia que podr\[ian tomar los datos, al crear factores se puede agregar niveles adicionales:

```{r}
blood <- factor(c("O","AB","A"),levels=c("A","B","AB","O"))
blood
```

### LISTAS

Se utiliza para almacenar un conjunto ordenado de valores. Permite recopilar diferentes tipos de valores:

```{r}
subject_name[1]
temperature[1]
flu_status[1]
gender[1]
blood[1]
```

Esta estructura no permite agregar todos los datos m\[edicos de un paciente en un objeto que se utilice de manera repetida. Similar al comando anterior se utiliza el comando list( ), adem\[as de permitir asignar un nombre para cada valor en la secuencia.

```{r}
subject1 <- list(fullname = subject_name[1],
temperature = temperature[1],
flu_status = flu_status[1],
gender = gender[1],
blood = blood[1])
```

Para poder visualizar los datos se utiliza:

```{r}
subject1$fullname
subject1$temperature
subject1$flu_status
subject1$gender
subject1$blood
```

```{r}
sujeto1[2]
sujeto1$temperatura
sujeto1[c("temperatura", "estado_gripe")]$temperatura
sujeto1[c("temperatura", "estado_gripe")]$estado_gripe
```

### Data frames

La estructura de datos de R más importante utilizada en el aprendizaje automático es data frames, esta estructura es similar a una hoja de cálculo (filas, columnas). Para explicar como crear un data frame utilizaremos los vectores de datos de pacientes que anteriormente se crearon.

```{r}
pt_data <- data.frame(subject_name, temperature, flu_status,gender, blood, stringsAsFactors = FALSE)
```

Como se observa se adiciono el parámetro stringsAsFactors = FALSE, al especificar esta opción impedimos que R convierta cada vector de caracteres en un factor. Los datos se muestran en forma de matriz.

```{r}
pt_data
```

Para extraer columnas enteras la forma más directa es referirse por el nombre:

```{r}
 pt_data$subject_name
 pt_data[c("temperature", "flu_status")]
```

Podemos extraer valores del data frame, sin embargo se debe especificar la posición de las filas (primero) y columnas (segundo).

```{r}
pt_data[1, 2]
```

En caso de necesitar mas de una fila o columna se lo debe escribir de la siguiente manera:

```{r}
 pt_data[c(1, 3), c(2, 4)]
```

Para extraer todas las filas o columnas, se debe dejar en blanco la parte de la fila o columna.

```{r}
pt_data[, 1]
pt_data[1, ]
pt_data[ , ]
```

Asi mismo para extraer valores en lista o excluir valores se puede utilizar los comandos que se utilizaron en vectores y listas.

```{r}
pt_data[c(1, 3), c("temperature", "gender")]
pt_data[-2, c(-1, -3, -5)]
```

### MATRICES Y ARRAYS

La matriz es una estructura bidimensional que puede contener cualquier tipo de de datos, aunque por lo general almacena datos numericos debido a que es utilizada para operaciones matemáticas.

Para crear una matriz se utiliza la función matrix( ) :

```{r}
m <- matrix(c('a', 'b', 'c', 'd'), nrow = 2)
m
m1 <- matrix(c('a', 'b', 'c', 'd'), ncol = 2)
m1
```
